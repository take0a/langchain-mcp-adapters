# LangChain MCP ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼

ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€[Anthropic Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) ãƒ„ãƒ¼ãƒ«ã‚’ [LangChain](https://github.com/langchain-ai/langchain) ãŠã‚ˆã³ [LangGraph](https://github.com/langchain-ai/langgraph) ã¨äº’æ›æ€§ã‚’æŒãŸã›ã‚‹è»½é‡ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚

![MCP](static/img/mcp.png)

## æ©Ÿèƒ½

- ğŸ› ï¸ MCPãƒ„ãƒ¼ãƒ«ã‚’[LangChainãƒ„ãƒ¼ãƒ«](https://python.langchain.com/docs/concepts/tools/)ã«å¤‰æ›ã—ã€[LangGraph](https://github.com/langchain-ai/langgraph)ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
- ğŸ“¦ è¤‡æ•°ã®MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã€ãã“ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install langchain-mcp-adapters
```

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ç°¡å˜ãªä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```bash
pip install langchain-mcp-adapters langgraph "langchain[openai]"

export OPENAI_API_KEY=<your_api_key>
```

### ã‚µãƒ¼ãƒãƒ¼

ã¾ãšã€æ•°å­—ã®åŠ ç®—ã¨ä¹—ç®—ãŒã§ãã‚‹MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚

```python
# math_server.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Math")

@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two numbers"""
    return a + b

@mcp.tool()
def multiply(a: int, b: int) -> int:
    """Multiply two numbers"""
    return a * b

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

### ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
# stdioæ¥ç¶šç”¨ã®ã‚µãƒ¼ãƒãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent

server_params = StdioServerParameters(
    command="python",
    # math_server.pyãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å®Œå…¨ãªçµ¶å¯¾ãƒ‘ã‚¹ã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚
    args=["/path/to/math_server.py"],
)

async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        # æ¥ç¶šã‚’åˆæœŸåŒ–ã™ã‚‹
        await session.initialize()

        # Get tools
        tools = await load_mcp_tools(session)

        # Create and run the agent
        agent = create_react_agent("openai:gpt-4.1", tools)
        agent_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})
```

## è¤‡æ•°ã®MCPã‚µãƒ¼ãƒãƒ¼

ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã¯ã€è¤‡æ•°ã®MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã€ãã“ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã‚‚ã§ãã¾ã™:

### ã‚µãƒ¼ãƒ

```python
# math_server.py
...

# weather_server.py
from typing import List
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Weather")

@mcp.tool()
async def get_weather(location: str) -> str:
    """Get weather for location."""
    return "It's always sunny in New York"

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```

```bash
python weather_server.py
```

### Client

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

client = MultiServerMCPClient(
    {
        "math": {
            "command": "python",
            # math_server.pyãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å®Œå…¨ãªçµ¶å¯¾ãƒ‘ã‚¹ã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚
            "args": ["/path/to/math_server.py"],
            "transport": "stdio",
        },
        "weather": {
            # å¤©æ°—äºˆå ±ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒ¼ãƒˆ8000â€‹â€‹ã§èµ·å‹•ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„
            "url": "http://localhost:8000/mcp/",
            "transport": "streamable_http",
        }
    }
)
tools = await client.get_tools()
agent = create_react_agent("openai:gpt-4.1", tools)
math_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})
weather_response = await agent.ainvoke({"messages": "what is the weather in nyc?"})
```

> [!note]
> ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ãƒ„ãƒ¼ãƒ«ã®å‘¼ã³å‡ºã—ã”ã¨ã«æ–°ã—ã„MCP `ClientSession`ãŒé–‹å§‹ã•ã‚Œã¾ã™ã€‚ç‰¹å®šã®ã‚µãƒ¼ãƒãƒ¼ã«å¯¾ã—ã¦æ˜ç¤ºçš„ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ãŸã„å ´åˆã¯ã€æ¬¡ã®ã‚ˆã†ã«ã—ã¾ã™:
>
>    ```python
>    from langchain_mcp_adapters.tools import load_mcp_tools
>
>    client = MultiServerMCPClient({...})
>    async with client.session("math") as session:
>        tools = await load_mcp_tools(session)
>    ```

## Streamable HTTP

MCP ã¯ã€[ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯èƒ½ãª HTTP](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http) ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

[ä¾‹](examples/servers/streamable-http-stateless/) ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯èƒ½ãª HTTP ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```bash
cd examples/servers/streamable-http-stateless/
uv run mcp-simple-streamablehttp-stateless --port 3000
```

ã‚ã‚‹ã„ã¯ã€ä¸Šè¨˜ã®ä¾‹ã®ã‚ˆã†ã« FastMCP ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

Python MCP SDK `streamablehttp_client` ã§ä½¿ç”¨ã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚ˆã†ã«ã—ã¾ã™:

```python
# examples/servers/streamable-http-stateless/ ã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

from langgraph.prebuilt import create_react_agent
from langchain_mcp_adapters.tools import load_mcp_tools

async with streamablehttp_client("http://localhost:3000/mcp/") as (read, write, _):
    async with ClientSession(read, write) as session:
        # Initialize the connection
        await session.initialize()

        # Get tools
        tools = await load_mcp_tools(session)
        agent = create_react_agent("openai:gpt-4.1", tools)
        math_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})
```

`MultiServerMCPClient` ã¨ä¸€ç·’ã«ä½¿ç”¨ã—ã¾ã™:

```python
# examples/servers/streamable-http-stateless/ ã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

client = MultiServerMCPClient(
    {
        "math": {
            "transport": "streamable_http",
            "url": "http://localhost:3000/mcp/"
        },
    }
)
tools = await client.get_tools()
agent = create_react_agent("openai:gpt-4.1", tools)
math_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})
```

## ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼ã®å—ã‘æ¸¡ã—

MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹éš›ã«ã€æ¥ç¶šè¨­å®šã®`headers`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆèªè¨¼ç”¨ã‚„ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãªã©ï¼‰ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯ä»¥ä¸‹ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

* `sse`
* `streamable_http`

### ä¾‹: `MultiServerMCPClient` ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¸¡ã™

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

client = MultiServerMCPClient(
    {
        "weather": {
            "transport": "streamable_http",
            "url": "http://localhost:8000/mcp",
            "headers": {
                "Authorization": "Bearer YOUR_TOKEN",
                "X-Custom-Header": "custom-value"
            },
        }
    }
)
tools = await client.get_tools()
agent = create_react_agent("openai:gpt-4.1", tools)
response = await agent.ainvoke({"messages": "what is the weather in nyc?"})
```

> `sse` ãŠã‚ˆã³ `streamable_http` ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã®ã¿ãŒãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ã€MCP ã‚µãƒ¼ãƒãƒ¼ã¸ã®ã™ã¹ã¦ã® HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã¨ã‚‚ã«æ¸¡ã•ã‚Œã¾ã™ã€‚


## LangGraph StateGraph ã¨ä½µç”¨ã™ã‚‹

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.graph import StateGraph, MessagesState, START
from langgraph.prebuilt import ToolNode, tools_condition

from langchain.chat_models import init_chat_model
model = init_chat_model("openai:gpt-4.1")

client = MultiServerMCPClient(
    {
        "math": {
            "command": "python",
            # math_server.pyãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å®Œå…¨ãªçµ¶å¯¾ãƒ‘ã‚¹ã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚
            "args": ["./examples/math_server.py"],
            "transport": "stdio",
        },
        "weather": {
            # å¤©æ°—äºˆå ±ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒ¼ãƒˆ8000â€‹â€‹ã§èµ·å‹•ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„
            "url": "http://localhost:8000/mcp/",
            "transport": "streamable_http",
        }
    }
)
tools = await client.get_tools()

def call_model(state: MessagesState):
    response = model.bind_tools(tools).invoke(state["messages"])
    return {"messages": response}

builder = StateGraph(MessagesState)
builder.add_node(call_model)
builder.add_node(ToolNode(tools))
builder.add_edge(START, "call_model")
builder.add_conditional_edges(
    "call_model",
    tools_condition,
)
builder.add_edge("tools", "call_model")
graph = builder.compile()
math_response = await graph.ainvoke({"messages": "what's (3 + 5) x 12?"})
weather_response = await graph.ainvoke({"messages": "what is the weather in nyc?"})
```

## LangGraph APIã‚µãƒ¼ãƒãƒ¼ã¨ä½µç”¨

> [!TIP]
> LangGraph APIã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ã„å§‹ã‚ã‚‹ã«ã¯ã€[ã“ã¡ã‚‰ã®ã‚¬ã‚¤ãƒ‰](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)ã‚’ã”è¦§ãã ã•ã„ã€‚

LangGraph APIã‚µãƒ¼ãƒãƒ¼ã§MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®è¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

```python
# graph.py
from contextlib import asynccontextmanager
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

async def make_graph():
    client = MultiServerMCPClient(
        {
            "math": {
                "command": "python",
                # Make sure to update to the full absolute path to your math_server.py file
                "args": ["/path/to/math_server.py"],
                "transport": "stdio",
            },
            "weather": {
                # make sure you start your weather server on port 8000
                "url": "http://localhost:8000/mcp/",
                "transport": "streamable_http",
            }
        }
    )
    tools = await client.get_tools()
    agent = create_react_agent("openai:gpt-4.1", tools)
    return agent
```

[`langgraph.json`](https://langchain-ai.github.io/langgraph/cloud/reference/cli/#configuration-file) ã§ã€ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ `make_graph` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„:

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./graph.py:make_graph"
  }
}
```

## LangChain ãƒ„ãƒ¼ãƒ«ã‚’ FastMCP ã‚µãƒ¼ãƒãƒ¼ã«è¿½åŠ ã™ã‚‹

`to_fastmcp` ã‚’ä½¿ç”¨ã—ã¦ LangChain ãƒ„ãƒ¼ãƒ«ã‚’ FastMCP ã«å¤‰æ›ã—ã€åˆæœŸåŒ–å­ã‚’ä½¿ç”¨ã—ã¦ `FastMCP` ã‚µãƒ¼ãƒãƒ¼ã«è¿½åŠ ã—ã¾ã™ã€‚

> [!NOTE]
> `tools` å¼•æ•°ã¯ `mcp >= 1.9.1` ä»¥é™ã® FastMCP ã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚

```python
from langchain_core.tools import tool
from langchain_mcp_adapters.tools import to_fastmcp
from mcp.server.fastmcp import FastMCP


@tool
def add(a: int, b: int) -> int:
    """Add two numbers"""
    return a + b


fastmcp_tool = to_fastmcp(add)

mcp = FastMCP("Math", tools=[fastmcp_tool])
mcp.run(transport="stdio")
```
